{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ohgcRnYPDfms"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, GlobalAveragePooling2D, Lambda, Reshape, multiply\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import ResNet50\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.optimizers import RMSprop,SGD\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0KCvgiQ1CT",
        "outputId": "dfef60bb-9910-49e7-fb49-645568f732e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"physical_devices = tf.config.experimental.list_physical_devices('GPU')\\nif len(physical_devices) > 0:\\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lz9z4T5SDh_u"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/AML.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G4ZZ46SSpfph"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/CALL.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t67jv3cU3ZKs"
      },
      "outputs": [],
      "source": [
        "#!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhucg5QjDsJh",
        "outputId": "fb0163b4-eb0d-4b47-b177-953736b308c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "leyendo imagenes de  AML/AML1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directorios leídos: 9\n",
            "Imágenes en cada directorio: [360, 360, 360, 360, 360, 360, 360, 360, 360]\n",
            "Suma total de imágenes en subdirectorios: 3240\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ruta de la carpeta de descargas\n",
        "# Directorio de descargas\n",
        "download_dir = os.path.expanduser(\"AML/AML1\")  # Ruta de la carpeta de descargas\n",
        "\n",
        "# Subdirectorios dentro de la carpeta de descargas\n",
        "#subdirs = [\"M0\", \"M1\", \"M2\", \"M3\", \"M4\"]\n",
        "subdirs = [\"all\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"sanos\"]\n",
        "\n",
        "# Listas para almacenar imágenes y recuentos\n",
        "images = []\n",
        "directories = []\n",
        "dircount = []\n",
        "\n",
        "# Tamaño deseado de las imágenes redimensionadas\n",
        "target_height = 150 #108, 200\n",
        "target_width = 250  #160, 300\n",
        "\n",
        "print(\"leyendo imagenes de \",download_dir)\n",
        "\n",
        "# Recorrer cada subdirectorio\n",
        "for subdir in subdirs:\n",
        "    subdir_path = os.path.join(download_dir, subdir)\n",
        "    images_count = 0\n",
        "\n",
        "    # Recorrer archivos en el subdirectorio\n",
        "    for root, _, filenames in os.walk(subdir_path):\n",
        "        for filename in filenames:\n",
        "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
        "                filepath = os.path.join(root, filename)\n",
        "\n",
        "                # Leer y redimensionar la imagen\n",
        "                image = imread(filepath)\n",
        "                image_resized = resize(image, (target_height, target_width), anti_aliasing=True, preserve_range=True)\n",
        "                images.append(image_resized)\n",
        "                #images.append(image)\n",
        "\n",
        "                images_count += 1\n",
        "\n",
        "    # Almacenar recuento y directorio\n",
        "    dircount.append(images_count)\n",
        "    directories.append(subdir)\n",
        "\n",
        "# Mostrar estadísticas finales\n",
        "print('Directorios leídos:', len(directories))\n",
        "print(\"Imágenes en cada directorio:\", dircount)\n",
        "print('Suma total de imágenes en subdirectorios:', sum(dircount))\n",
        "\n",
        "# Convertir la lista de imágenes a un array de numpy\n",
        "#images_array = np.array(images)\n",
        "'''for i in range(len(images)):\n",
        "  images[i] = np.array(images[i], dtype=np.uint8)'''\n",
        "# Convertir las imágenes a RGB\n",
        "'''for i in range(len(images)):\n",
        "  images[i] = images[i][..., :3]\n",
        "'''\n",
        "type(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NEo9ygiL0c7I",
        "outputId": "6e8ae10a-a351-4237-c617-c5557fb2ccd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'AML/AML1'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Directorio que contiene las imágenes\n",
        "directorio_imagenes = os.path.expanduser(\"AML/AML1\")\n",
        "directorio_imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZgms5W3RFb"
      },
      "source": [
        "# Nueva sección\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5YIhO_4Dw-R",
        "outputId": "2c1775dd-77f1-4f3c-d0a9-c2ad5f93f0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de etiquetas creadas:  3240\n"
          ]
        }
      ],
      "source": [
        "labels = []\n",
        "indice = 0\n",
        "for cantidad in dircount:\n",
        "  for i in range(cantidad):\n",
        "    labels.append(indice)\n",
        "  indice = indice + 1\n",
        "print(\"Cantidad de etiquetas creadas: \", len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jYjrTBaD1My",
        "outputId": "78d37cd1-d1db-4ad3-b6a3-1b6b274b5bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 all\n",
            "1 M1\n",
            "2 M2\n",
            "3 M3\n",
            "4 M4\n",
            "5 M5\n",
            "6 M6\n",
            "7 M7\n",
            "8 sanos\n"
          ]
        }
      ],
      "source": [
        "AMLI=[]\n",
        "indice=0\n",
        "for directorio in directories:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    AMLI.append(name[len(name)-1])\n",
        "    indice=indice+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkGpN5QQD1yP",
        "outputId": "4177a290-0ada-49a6-e413-b7897ba38f44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(AMLI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrxXspo2D3kN",
        "outputId": "47ba61a7-0bcb-47ed-aede-f286f8d60775"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['all', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'sanos']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AMLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rGyIYoXID6fC"
      },
      "outputs": [],
      "source": [
        "#for img in images:\n",
        "    #print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8StK0v7GD_gG",
        "outputId": "787fc6d7-eefd-45ea-e548-65e91c23c23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of outputs :  9\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.array(labels)\n",
        "#X = images\n",
        "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "classes = np.unique(y)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)\n",
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV8ofhX1EEE4",
        "outputId": "df8f2d77-6463-45ce-ab0a-bda1d8124de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape :  (2592, 150, 250, 3) (2592,)\n",
            "Testing data shape :  (648, 150, 250, 3) (648,)\n",
            "(150, 250, 3)\n"
          ]
        }
      ],
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir listas a arrays NumPy\n",
        "#X_train = np.array(X_train)\n",
        "#X_test = np.array(X_test)\n",
        "\n",
        "# Normalizamos como float32 para poder dividirlos entre 0 y 1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Valores entre 0..1\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('Training data shape : ', X_train.shape, y_train.shape)\n",
        "print('Testing data shape : ', X_test.shape, y_test.shape)\n",
        "\n",
        "img_size = X[0].shape\n",
        "print(img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RFPqepCgYt2t"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Codificar las etiquetas\n",
        "y_train_encoded = to_categorical(y_train, num_classes=nClasses)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=nClasses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTp_jLP4LKU"
      },
      "source": [
        "# Modelos\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r-c5RztLlzWS"
      },
      "outputs": [],
      "source": [
        "# Modelo SENet\n",
        "def se_block(input_tensor, ratio=16):\n",
        "    channel_count = input_tensor.shape[-1]\n",
        "\n",
        "    # Global average pooling que preserva las dimensiones originales\n",
        "    x = GlobalAveragePooling2D()(input_tensor)\n",
        "\n",
        "    # Capas Dense para aprender los pesos de excitación\n",
        "    x = Dense(channel_count // ratio, activation='relu')(x)\n",
        "    x = Dense(channel_count, activation='sigmoid')(x)\n",
        "\n",
        "    # Redefinir las dimensiones para poder aplicar capas Dense\n",
        "    #x = Reshape((1, 1, channel_count))(x)\n",
        "\n",
        "    # Multiplicar el tensor de entrada por los pesos aprendidos\n",
        "    x = multiply([input_tensor, x])\n",
        "    return x\n",
        "\n",
        "def senet_model(input_shape=img_size, ratio=16):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    x = Conv2D(256, (5, 5), padding='same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "    x = se_block(x, ratio=ratio)\n",
        "\n",
        "    #x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "    # Aplanar el tensor antes de la capa Dense\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(1024, activation='relu')(x)  # Agregada una capa densa\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)  # Agregada capa de dropout\n",
        "\n",
        "    output_tensor = Dense(nClasses, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    return model\n",
        "\n",
        "senet_model = senet_model(input_shape=img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs1 = 31\n",
        "batch_size1 = 32\n",
        "train_size1 =2592\n",
        "\n",
        "initial_learning_rate1 = 0.0001\n",
        "final_learning_rate1 = 0.00001\n",
        "learning_rate_decay_factor1 = (final_learning_rate1 / initial_learning_rate1)**(1/epochs1)\n",
        "steps_per_epoch1 = int(train_size1/batch_size1)\n",
        "\n",
        "lr_schedule1 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "                initial_learning_rate=initial_learning_rate1,\n",
        "                decay_steps=steps_per_epoch1,\n",
        "                decay_rate=learning_rate_decay_factor1,\n",
        "                staircase=True)\n",
        "# Define optimizer using the learning rate schedule\n",
        "optimizer1 = RMSprop(learning_rate=lr_schedule1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4TVGuXEGQ1Cd"
      },
      "outputs": [],
      "source": [
        "senet_model.compile(optimizer=optimizer1, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4k8oFuj-IIor"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/31\n",
            "81/81 [==============================] - 10s 87ms/step - loss: 2.0299 - accuracy: 0.2079 - val_loss: 1.7751 - val_accuracy: 0.3441\n",
            "Epoch 2/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 1.7544 - accuracy: 0.3391 - val_loss: 1.8682 - val_accuracy: 0.3117\n",
            "Epoch 3/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 1.5919 - accuracy: 0.4244 - val_loss: 1.4560 - val_accuracy: 0.4599\n",
            "Epoch 4/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 1.4429 - accuracy: 0.4776 - val_loss: 1.3718 - val_accuracy: 0.4738\n",
            "Epoch 5/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 1.2949 - accuracy: 0.5382 - val_loss: 1.3163 - val_accuracy: 0.5077\n",
            "Epoch 6/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 1.1679 - accuracy: 0.5876 - val_loss: 1.1622 - val_accuracy: 0.5818\n",
            "Epoch 7/31\n",
            "81/81 [==============================] - 5s 57ms/step - loss: 1.0383 - accuracy: 0.6343 - val_loss: 1.0452 - val_accuracy: 0.6466\n",
            "Epoch 8/31\n",
            "81/81 [==============================] - 5s 57ms/step - loss: 0.9337 - accuracy: 0.6825 - val_loss: 0.9987 - val_accuracy: 0.6605\n",
            "Epoch 9/31\n",
            "81/81 [==============================] - 5s 59ms/step - loss: 0.8463 - accuracy: 0.7114 - val_loss: 1.0752 - val_accuracy: 0.6003\n",
            "Epoch 10/31\n",
            "81/81 [==============================] - 5s 57ms/step - loss: 0.7516 - accuracy: 0.7612 - val_loss: 0.9147 - val_accuracy: 0.6775\n",
            "Epoch 11/31\n",
            "81/81 [==============================] - 5s 57ms/step - loss: 0.6687 - accuracy: 0.7812 - val_loss: 0.9722 - val_accuracy: 0.6682\n",
            "Epoch 12/31\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 0.6009 - accuracy: 0.8071 - val_loss: 0.8433 - val_accuracy: 0.7099\n",
            "Epoch 13/31\n",
            "81/81 [==============================] - 5s 59ms/step - loss: 0.5309 - accuracy: 0.8356 - val_loss: 0.7908 - val_accuracy: 0.7577\n",
            "Epoch 14/31\n",
            "81/81 [==============================] - 5s 59ms/step - loss: 0.4745 - accuracy: 0.8542 - val_loss: 0.8471 - val_accuracy: 0.7392\n",
            "Epoch 15/31\n",
            "81/81 [==============================] - 5s 58ms/step - loss: 0.4280 - accuracy: 0.8708 - val_loss: 0.7650 - val_accuracy: 0.7546\n",
            "Epoch 16/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.3856 - accuracy: 0.8846 - val_loss: 0.7920 - val_accuracy: 0.7485\n",
            "Epoch 17/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.3430 - accuracy: 0.8947 - val_loss: 0.7146 - val_accuracy: 0.7639\n",
            "Epoch 18/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.3050 - accuracy: 0.9136 - val_loss: 0.6832 - val_accuracy: 0.7685\n",
            "Epoch 19/31\n",
            "81/81 [==============================] - 5s 59ms/step - loss: 0.2746 - accuracy: 0.9217 - val_loss: 0.7024 - val_accuracy: 0.7778\n",
            "Epoch 20/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.2506 - accuracy: 0.9333 - val_loss: 0.6617 - val_accuracy: 0.7870\n",
            "Epoch 21/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.2297 - accuracy: 0.9336 - val_loss: 0.6604 - val_accuracy: 0.7778\n",
            "Epoch 22/31\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 0.2007 - accuracy: 0.9471 - val_loss: 0.6712 - val_accuracy: 0.7978\n",
            "Epoch 23/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.1799 - accuracy: 0.9549 - val_loss: 0.6602 - val_accuracy: 0.7886\n",
            "Epoch 24/31\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 0.1614 - accuracy: 0.9645 - val_loss: 0.6827 - val_accuracy: 0.7963\n",
            "Epoch 25/31\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 0.1515 - accuracy: 0.9618 - val_loss: 0.6926 - val_accuracy: 0.7778\n",
            "Epoch 26/31\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 0.1306 - accuracy: 0.9753 - val_loss: 0.6832 - val_accuracy: 0.7793\n",
            "Epoch 27/31\n",
            "81/81 [==============================] - 6s 68ms/step - loss: 0.1235 - accuracy: 0.9711 - val_loss: 0.6673 - val_accuracy: 0.7870\n",
            "Epoch 28/31\n",
            "81/81 [==============================] - 6s 69ms/step - loss: 0.1082 - accuracy: 0.9799 - val_loss: 0.7023 - val_accuracy: 0.7809\n",
            "Epoch 29/31\n",
            "81/81 [==============================] - 5s 67ms/step - loss: 0.1039 - accuracy: 0.9811 - val_loss: 0.6900 - val_accuracy: 0.7870\n",
            "Epoch 30/31\n",
            "81/81 [==============================] - 5s 65ms/step - loss: 0.0901 - accuracy: 0.9830 - val_loss: 0.6996 - val_accuracy: 0.7809\n",
            "Epoch 31/31\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 0.0850 - accuracy: 0.9888 - val_loss: 0.6908 - val_accuracy: 0.7901\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2ae0007a440>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "senet_model.fit(X_train, y_train_encoded, epochs=epochs1, batch_size=batch_size1, validation_data=(X_test, y_test_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "senet_model.save('senet_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
