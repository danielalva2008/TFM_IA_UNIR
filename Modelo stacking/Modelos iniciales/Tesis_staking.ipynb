{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ohgcRnYPDfms"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, GlobalAveragePooling2D, Lambda, Reshape, multiply\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import ResNet50\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.optimizers import RMSprop,SGD\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48-NZrArUgub",
        "outputId": "a58fbc5b-60a4-47d2-b097-5dc8aa8d5804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz9z4T5SDh_u"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/AML.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4ZZ46SSpfph"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/CALL.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t67jv3cU3ZKs"
      },
      "outputs": [],
      "source": [
        "#!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# Ruta de la carpeta de descargas\n",
        "download_dir = os.path.expanduser(\"AML\")  # Ruta de la carpeta de descargas\n",
        "\n",
        "# Subdirectorios dentro de la carpeta de descargas\n",
        "subdirs = [\"all\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"sanos\"]\n",
        "\n",
        "# Carpeta para guardar imágenes aumentadas\n",
        "output_dir_base = os.path.join(download_dir, \"AML1\")\n",
        "os.makedirs(output_dir_base, exist_ok=True)\n",
        "\n",
        "# Configuración de aumentadores\n",
        "seq_gaussian_noise = iaa.Sequential([iaa.AdditiveGaussianNoise(scale=(0, 0.2*255))])\n",
        "seq_brightness = iaa.Sequential([iaa.Multiply((1.2, 1.5))])\n",
        "seq_rotation = iaa.Sequential([iaa.Affine(rotate=25)])\n",
        "seq_grayscale = iaa.Sequential([iaa.Grayscale(alpha=(0.0, 1.0))])\n",
        "seq_horizontal_flip = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "seq_vertical_flip = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "seq_shear = iaa.Sequential([iaa.Affine(shear=(-25, 25))])\n",
        "seq_zoom = iaa.Sequential([iaa.Affine(scale=(1.5, 1.5))])\n",
        "\n",
        "# Listas para almacenar imágenes y recuentos\n",
        "directories = []\n",
        "dircount = []\n",
        "\n",
        "print(\"Leyendo imágenes de\", download_dir)\n",
        "\n",
        "# Recorrer cada subdirectorio\n",
        "for subdir in subdirs:\n",
        "    subdir_path = os.path.join(download_dir, subdir)\n",
        "    output_dir = os.path.join(output_dir_base, subdir)\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create subdirectory if it doesn't exist\n",
        "    images_count = 0\n",
        "\n",
        "    # Recorrer archivos en el subdirectorio\n",
        "    for root, _, filenames in os.walk(subdir_path):\n",
        "        for filename in filenames:\n",
        "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
        "                filepath = os.path.join(root, filename)\n",
        "\n",
        "                # Leer la imagen y convertirla a array de numpy\n",
        "                image = np.array(Image.open(filepath))\n",
        "\n",
        "                # Guardar la imagen original en el mismo subdirectorio\n",
        "                output_path_original = os.path.join(output_dir, filename[:-4] + \"_original.jpg\")\n",
        "                Image.fromarray(image).convert(\"RGB\").save(output_path_original)\n",
        "\n",
        "                # Aplicar ruido gaussiano\n",
        "                image_gaussian = seq_gaussian_noise.augment_image(image)\n",
        "                output_path_gaussian = os.path.join(output_dir, filename[:-4] + \"_g.jpg\")\n",
        "                Image.fromarray(image_gaussian).convert(\"RGB\").save(output_path_gaussian)\n",
        "\n",
        "                # Aplicar aumento de brillo\n",
        "                image_brightness = seq_brightness.augment_image(image)\n",
        "                output_path_brightness = os.path.join(output_dir, filename[:-4] + \"_b.jpg\")\n",
        "                Image.fromarray(image_brightness).convert(\"RGB\").save(output_path_brightness)\n",
        "\n",
        "                # Aplicar rotación a la izquierda de 90 grados\n",
        "                image_rotation = seq_rotation.augment_image(image)\n",
        "                output_path_rotation = os.path.join(output_dir, filename[:-4] + \"_r.jpg\")\n",
        "                Image.fromarray(image_rotation).convert(\"RGB\").save(output_path_rotation)\n",
        "\n",
        "                # Convertir la imagen a formato RGB antes de aplicar grayscaling\n",
        "                image_rgb = Image.fromarray(image).convert(\"RGB\")\n",
        "                image_grayscale = seq_grayscale.augment_image(np.array(image_rgb))\n",
        "\n",
        "                # Guardar la imagen grayscaled en el mismo subdirectorio\n",
        "                output_path_grayscale = os.path.join(output_dir, filename[:-4] + \"_gray.jpg\")\n",
        "                Image.fromarray(image_grayscale).save(output_path_grayscale)\n",
        "\n",
        "                # Aplicar reflexión horizontal\n",
        "                image_horizontal_flip = seq_horizontal_flip.augment_image(image)\n",
        "                output_path_hflip = os.path.join(output_dir, filename[:-4] + \"_hflip.jpg\")\n",
        "                Image.fromarray(image_horizontal_flip).convert(\"RGB\").save(output_path_hflip)\n",
        "\n",
        "                # Aplicar reflexión vertical\n",
        "                image_vertical_flip = seq_vertical_flip.augment_image(image)\n",
        "                output_path_vflip = os.path.join(output_dir, filename[:-4] + \"_vflip.jpg\")\n",
        "                Image.fromarray(image_vertical_flip).convert(\"RGB\").save(output_path_vflip)\n",
        "\n",
        "                # Aplicar shearing\n",
        "                image_shear = seq_shear.augment_image(image)\n",
        "                output_path_shear = os.path.join(output_dir, filename[:-4] + \"_shear.jpg\")\n",
        "                Image.fromarray(image_shear).convert(\"RGB\").save(output_path_shear)\n",
        "\n",
        "                # Aplicar zoom con un factor de 0.2\n",
        "                image_zoom = seq_zoom.augment_image(image)\n",
        "                output_path_zoom = os.path.join(output_dir, filename[:-4] + \"_zoom.jpg\")\n",
        "                Image.fromarray(image_zoom).convert(\"RGB\").save(output_path_zoom)\n",
        "\n",
        "                images_count += 1\n",
        "\n",
        "    # Almacenar recuento y directorio\n",
        "    dircount.append(images_count)\n",
        "    directories.append(subdir)\n",
        "\n",
        "# Mostrar estadísticas finales\n",
        "print('Directorios leídos:', len(directories))\n",
        "print(\"Imágenes en cada directorio:\", dircount)\n",
        "print('Suma total de imágenes en subdirectorios:', sum(dircount))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_8gI1O4jTcF",
        "outputId": "40f206d9-f2cf-4cc7-eccc-9f6b758112a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo imágenes de AML\n",
            "Directorios leídos: 9\n",
            "Imágenes en cada directorio: [40, 40, 40, 40, 40, 40, 40, 40, 40]\n",
            "Suma total de imágenes en subdirectorios: 360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhucg5QjDsJh",
        "outputId": "a9193909-8d8d-4f1d-fdc5-c8e3fa9db310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leyendo imagenes de  AML/AML1\n",
            "Directorios leídos: 9\n",
            "Imágenes en cada directorio: [360, 360, 360, 360, 360, 360, 360, 360, 360]\n",
            "Suma total de imágenes en subdirectorios: 3240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Ruta de la carpeta de descargas\n",
        "# Directorio de descargas\n",
        "download_dir = os.path.expanduser(\"AML/AML1\")  # Ruta de la carpeta de descargas\n",
        "\n",
        "# Subdirectorios dentro de la carpeta de descargas\n",
        "#subdirs = [\"M0\", \"M1\", \"M2\", \"M3\", \"M4\"]\n",
        "subdirs = [\"all\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"sanos\"]\n",
        "\n",
        "# Listas para almacenar imágenes y recuentos\n",
        "images = []\n",
        "directories = []\n",
        "dircount = []\n",
        "\n",
        "# Tamaño deseado de las imágenes redimensionadas\n",
        "target_height = 150 #108, 200\n",
        "target_width = 250  #160, 300\n",
        "\n",
        "print(\"leyendo imagenes de \",download_dir)\n",
        "\n",
        "# Recorrer cada subdirectorio\n",
        "for subdir in subdirs:\n",
        "    subdir_path = os.path.join(download_dir, subdir)\n",
        "    images_count = 0\n",
        "\n",
        "    # Recorrer archivos en el subdirectorio\n",
        "    for root, _, filenames in os.walk(subdir_path):\n",
        "        for filename in filenames:\n",
        "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
        "                filepath = os.path.join(root, filename)\n",
        "\n",
        "                # Leer y redimensionar la imagen\n",
        "                image = imread(filepath)\n",
        "                image_resized = resize(image, (target_height, target_width), anti_aliasing=True, preserve_range=True)\n",
        "                images.append(image_resized)\n",
        "                #images.append(image)\n",
        "\n",
        "                images_count += 1\n",
        "\n",
        "    # Almacenar recuento y directorio\n",
        "    dircount.append(images_count)\n",
        "    directories.append(subdir)\n",
        "\n",
        "# Mostrar estadísticas finales\n",
        "print('Directorios leídos:', len(directories))\n",
        "print(\"Imágenes en cada directorio:\", dircount)\n",
        "print('Suma total de imágenes en subdirectorios:', sum(dircount))\n",
        "\n",
        "# Convertir la lista de imágenes a un array de numpy\n",
        "#images_array = np.array(images)\n",
        "'''for i in range(len(images)):\n",
        "  images[i] = np.array(images[i], dtype=np.uint8)'''\n",
        "# Convertir las imágenes a RGB\n",
        "'''for i in range(len(images)):\n",
        "  images[i] = images[i][..., :3]\n",
        "'''\n",
        "type(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NEo9ygiL0c7I",
        "outputId": "2aa738fe-8a7e-4b30-e717-6985f7e56959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AML/AML1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Directorio que contiene las imágenes\n",
        "directorio_imagenes = os.path.expanduser(\"AML/AML1\")\n",
        "directorio_imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZgms5W3RFb"
      },
      "source": [
        "# Nueva sección\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5YIhO_4Dw-R",
        "outputId": "0748ef0d-2fa1-4ef7-ae8e-a79a7fedbccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de etiquetas creadas:  3240\n"
          ]
        }
      ],
      "source": [
        "labels = []\n",
        "indice = 0\n",
        "for cantidad in dircount:\n",
        "  for i in range(cantidad):\n",
        "    labels.append(indice)\n",
        "  indice = indice + 1\n",
        "print(\"Cantidad de etiquetas creadas: \", len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jYjrTBaD1My",
        "outputId": "f467f2d9-e3ed-4b48-94ae-1e860978aa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 all\n",
            "1 M1\n",
            "2 M2\n",
            "3 M3\n",
            "4 M4\n",
            "5 M5\n",
            "6 M6\n",
            "7 M7\n",
            "8 sanos\n"
          ]
        }
      ],
      "source": [
        "AMLI=[]\n",
        "indice=0\n",
        "for directorio in directories:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    AMLI.append(name[len(name)-1])\n",
        "    indice=indice+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkGpN5QQD1yP",
        "outputId": "78cfacfe-5595-454c-cb62-0001a2924d21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(AMLI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrxXspo2D3kN",
        "outputId": "d1fda9be-77cf-4811-bdca-535ed8b0b324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['all', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'sanos']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "AMLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8StK0v7GD_gG",
        "outputId": "387b7d32-13c4-4976-92d8-b63ee8071926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outputs :  9\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y = np.array(labels)\n",
        "#X = images\n",
        "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "classes = np.unique(y)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)\n",
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV8ofhX1EEE4",
        "outputId": "6e449606-7797-4ec7-ae94-2df509d37ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape :  (2592, 150, 250, 3) (2592,)\n",
            "Testing data shape :  (648, 150, 250, 3) (648,)\n",
            "(150, 250, 3)\n"
          ]
        }
      ],
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir listas a arrays NumPy\n",
        "#X_train = np.array(X_train)\n",
        "#X_test = np.array(X_test)\n",
        "\n",
        "# Normalizamos como float32 para poder dividirlos entre 0 y 1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Valores entre 0..1\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('Training data shape : ', X_train.shape, y_train.shape)\n",
        "print('Testing data shape : ', X_test.shape, y_test.shape)\n",
        "\n",
        "img_size = X[0].shape\n",
        "print(img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RFPqepCgYt2t"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Codificar las etiquetas\n",
        "y_train_encoded = to_categorical(y_train, num_classes=nClasses)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=nClasses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTp_jLP4LKU"
      },
      "source": [
        "# Modelos\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i6Bey6vhUguf"
      },
      "outputs": [],
      "source": [
        "# Cargar modelos preentrenados\n",
        "alexnet_model = load_model(\"AlexNet_model.h5\")\n",
        "resnet_model = load_model(\"resnet_model.h5\")\n",
        "senet_model = load_model(\"senet_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-hTLaTGe7ha"
      },
      "outputs": [],
      "source": [
        "# Hacer predicciones\n",
        "#y_pred_alexnet = alexnet_model.predict(X_test)\n",
        "#y_pred_resnet = resnet_model.predict(X_test)\n",
        "#y_pred_senet = senet_model.predict(X_test)\n",
        "\n",
        "#alexnet_predictions = alexnet_model.predict(X_train)\n",
        "#resnet_predictions = resnet_model.predict(X_train)\n",
        "#senet_predictions = senet_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC0Vm9FxUgug",
        "outputId": "2bad7c54-ca82-472d-b479-b6e5aea95e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de y_test: <class 'numpy.ndarray'>\n",
            "Valores únicos en y_test: [0 1 2 3 4 5 6 7 8]\n"
          ]
        }
      ],
      "source": [
        "print(\"Tipo de y_test:\", type(y_test))\n",
        "print(\"Valores únicos en y_test:\", np.unique(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plJ8KFjwUgug",
        "outputId": "37456948-ce4a-4014-e0e9-bd98a5c8e5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/81 [==============================] - 3s 9ms/step\n",
            "21/21 [==============================] - 1s 23ms/step\n",
            "81/81 [==============================] - 8s 67ms/step\n",
            "21/21 [==============================] - 3s 113ms/step\n",
            "81/81 [==============================] - 1s 9ms/step\n",
            "21/21 [==============================] - 0s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "def extract_features(model, X_train, X_test):\n",
        "    features_train = model.predict(X_train)\n",
        "    features_test = model.predict(X_test)\n",
        "    return features_train, features_test\n",
        "\n",
        "# Extract features for each model\n",
        "alexnet_features_train, alexnet_features_test = extract_features(alexnet_model, X_train, X_test)\n",
        "resnet_features_train, resnet_features_test = extract_features(resnet_model, X_train, X_test)\n",
        "senet_features_train, senet_features_test = extract_features(senet_model, X_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JCsIt_4bUgug"
      },
      "outputs": [],
      "source": [
        "stacked_features_train = np.concatenate([alexnet_features_train, resnet_features_train, senet_features_train], axis=1)\n",
        "stacked_features_test = np.concatenate([alexnet_features_test, resnet_features_test, senet_features_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nIvaWZ3aUgug"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define the meta-learner architecture\n",
        "meta_learner = Sequential()\n",
        "meta_learner.add(Dense(64, activation='relu', input_shape=(stacked_features_train.shape[1],)))\n",
        "meta_learner.add(Dense(nClasses, activation='softmax'))  # Adjust nClasses to match your problem\n",
        "\n",
        "# Compile the meta-learner\n",
        "meta_learner.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxRhnEB3Ugug",
        "outputId": "12cb7479-c1a4-438d-d1c9-7964af6d592e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 1.5186 - accuracy: 0.8221\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.9734\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9749\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9749\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9749\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9753\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9757\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9765\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9772\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fbcf4515540>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "meta_learner.fit(stacked_features_train, y_train_encoded, epochs=10, batch_size=32)  # Adjust epochs and batch_size as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcP0pMTtUgug",
        "outputId": "080b0d83-5aff-4414-8d96-65a7029befce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "stacked_predictions = meta_learner.predict(stacked_features_test)\n",
        "# Evaluate using appropriate metrics (e.g., accuracy, precision, recall, F1-score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Predict using the meta-learner on the test set\n",
        "final_predictions_test = meta_learner.predict(stacked_features_test)\n",
        "final_predictions_test_classes = np.argmax(final_predictions_test, axis=1)\n",
        "\n",
        "# Convert one-hot encoded labels back to categorical labels\n",
        "y_test_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_classes, final_predictions_test_classes)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Display classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_classes, final_predictions_test_classes))\n",
        "\n",
        "# Display confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, final_predictions_test_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxpnHMOjo_ct",
        "outputId": "5a39a632-c1fa-4f2c-a4ed-35cfdb6eaf6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.9722222222222222\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99        91\n",
            "           1       0.95      0.96      0.96        80\n",
            "           2       0.96      0.96      0.96        80\n",
            "           3       0.99      0.97      0.98        68\n",
            "           4       0.97      0.94      0.95        65\n",
            "           5       0.94      0.98      0.96        66\n",
            "           6       0.99      0.97      0.98        69\n",
            "           7       0.97      0.98      0.97        59\n",
            "           8       1.00      0.99      0.99        70\n",
            "\n",
            "    accuracy                           0.97       648\n",
            "   macro avg       0.97      0.97      0.97       648\n",
            "weighted avg       0.97      0.97      0.97       648\n",
            "\n",
            "Confusion Matrix:\n",
            "[[90  0  1  0  0  0  0  0  0]\n",
            " [ 0 77  0  1  1  1  0  0  0]\n",
            " [ 0  3 77  0  0  0  0  0  0]\n",
            " [ 0  0  0 66  1  1  0  0  0]\n",
            " [ 0  1  0  0 61  2  0  1  0]\n",
            " [ 0  0  0  0  0 65  1  0  0]\n",
            " [ 0  0  1  0  0  0 67  1  0]\n",
            " [ 0  0  1  0  0  0  0 58  0]\n",
            " [ 1  0  0  0  0  0  0  0 69]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}